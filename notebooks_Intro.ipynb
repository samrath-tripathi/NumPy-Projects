{
  "metadata": {
    "kernelspec": {
      "display_name": "Python (Pyodide)",
      "language": "python",
      "name": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "ba8ce7b4-e738-41cf-8776-a22f1e5a2268",
      "cell_type": "code",
      "source": "# We will be using Least square regression to give a linear model for the volatility of RMS. We derive a matrix X that is a design matrix \n# X represents 4 volatility factors over 5 time points (Feb 2026) derived from daily returns. They are lag 1 rolling volatilities \n\nimport numpy as np\n\n# 5x5 design matrix: intercept + 4 factors (BHP, RIO, FMG, ASX200)\nX = np.array([\n    [1.0, 0.0495, 0.0097, 0.0298, 0.0095],\n    [1.0, 0.0205, 0.0012, 0.0229, 0.0153],\n    [1.0, 0.0139, 0.0050, 0.0251, 0.0201],\n    [1.0, 0.0151, 0.0150, 0.0265, 0.0309],\n    [1.0, 0.0361, 0.0100, 0.0030, 0.0113]\n])\n\n# RMS rolling volatilities \ny_row = np.array([0.0226, 0.0168, 0.0076, 0.0329, 0.0550])\ny = y_row.reshape(-1,1)\n\n# Columns of X are rolling volatilities for BHP, RIO, FMG, ASX200 Market factor respectively. \n# Y is the rolling volatilities RMS. We orthogonally project Y onto factor space to minimise least square error\n# We are hence deriving RMS volatility as a function of lagged volatilities of other stocks\n# Factor subspace contains all volatility deviations that are explainable by those factors.\n\n# Scale factor columns (columns 1-4) by 0.01 for interpretability\nX_scaled = X.copy()\nX_scaled[:,1:] = X[:,1:] / 0.01\n\n# recall normal equation y = (X.T X)^-1 X.T y \n\nX_trans = X_scaled.T          # X^T\nXtX = X_trans @ X_scaled      # X^T X\ninv_XtX = np.linalg.inv(XtX)  # (X^T X)^(-1)\nXty = X_trans @ y             # X^T Y\n\n\nBeta = inv_XtX @ Xty          # coefficents\n\nB = Beta[0,0]\ncoef_BHP = Beta[1,0]\ncoef_RIO = Beta[2,0]\ncoef_FMG = Beta[3,0]\ncoef_ASX = Beta[4,0]\n\n# Hence our linear regression reads\nprint(\"Linear regression is:\", B, \" +\", coef_BHP, \"BHP +\", coef_RIO, \"RIO +\", coef_FMG, \"FMG +\", coef_ASX, \"ASX\")\n\n# Our projection onto factor space reads\nproj_y = X @ Beta\n\nd1 = proj_y[0,0]\nd2 = proj_y[1,0]\nd3 = proj_y[2,0]\nd4 = proj_y[3,0]\nd5 = proj_y[4,0]\nmag_proj = np.linalg.norm(proj_y)\n\nprint(\"Hence, for first period RMS volatility by factors and intercept is predicted as\", -d1,\n      \"second period is\", -d2,\n      \"third period is\", -d3,                                              # the negative signs here are for cohessive interpretability\n      \"fourth period is\", -d4,\n      \"fifth period is\", -d5,\n      \"total volatility explained by factors is hence\", mag_proj)\n\n# Other statistical data obtained\nidyo = y - proj_y\n\nd1u = idyo[0,0]\nd2u = idyo[1,0]\nd3u = idyo[2,0]\nd4u = idyo[3,0]\nd5u = idyo[4,0]\n\nmag_y = np.linalg.norm(y)\nmag_idyo = np.linalg.norm(idyo)\n\nprint(\"Hence, volatility unexplained by factors for first period is\", d1u,\n      \"second is\", d2u,\n      \"third is\", d3u,\n      \"fourth is\", d4u,\n      \"fifth is\", d5u,\n      \"Total volatility unexplained is\", mag_idyo,\n      \"Total volatility of RMS is\", mag_y)\n",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Linear regression is: -0.061775757283532684  + 0.026491569013266325 BHP + -0.030385524932603047 RIO + -0.02221671225052546 FMG + 0.05149710774637484 ASX\nHence, for first period RMS volatility by factors and intercept is predicted as 0.06093199971069734 second period is 0.060989999710697344 third period is 0.061081999710697346 fourth period is 0.06082899971069735 fifth period is 0.060607999710697344 total volatility explained by factors is hence 0.13615063781286088\nHence, volatility unexplained by factors for first period is 0.08353199971069734 second is 0.07778999971069735 third is 0.06868199971069734 fourth is 0.09372899971069734 fifth is 0.11560799971069735 Total volatility unexplained is 0.19974090992782367 Total volatility of RMS is 0.07041427412108996\n"
        }
      ],
      "execution_count": 51
    },
    {
      "id": "a455fc17-41f9-4083-8c90-46062d39f2a2",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4f3e0dbf-fd0e-4975-979a-fa96a1e5b4a3",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "2a722c8d-9514-4869-9017-0fe32e5ce322",
      "cell_type": "code",
      "source": "# Here, we construct a matrix whose columns are RMS, BHP, RIO over 3 periods of returns. We can take this to be a portfolio of sorts\n# PCA via SVD on 3-stock portfolio to identify dominant variance directions and project daily returns onto these PCs for interpretation.\n# This helps us reduce dimensions of our portfolio, we can analyse volatility contributions of stocks and reduce risk of portfolio.\n\nimport numpy as np\n\nA = np.array([\n    [-0.01745,  0.01205,  0.00325],  # 17 Feb: RMS, BHP, RIO\n    [ 0.01549, -0.01045, -0.00233],  # 16 Feb\n    [-0.03624,  0.00854,  0.00555]   # 13 Feb\n])\n\n# We are centering matrix of returns by the mean to capture variance rather than arbitary numerical percentages\n\nA_centered = A - A.mean(axis=0)\ncov_matrix = (A_centered.T @ A_centered) / (A.shape[0]-1)\n\neigvals, eigvecs = np.linalg.eig(cov_matrix)\neigvals[eigvals < 0] = 0                        # for this trivial project we are not concerned with eigenobjects over complex field\nsv = np.sqrt(eigvals)\nS = np.diag(sv)\n\nv1 = eigvecs[:,0].reshape(-1,1)\nv2 = eigvecs[:,1].reshape(-1,1)\nv3 = eigvecs[:,2].reshape(-1,1)\n\ne1 = v1/np.linalg.norm(v1)  \nw2 = v2 - np.dot(v2.T,e1) * e1 \ne2 = w2/np.linalg.norm(w2) \nw3 = v3 - np.dot(v3.T,e1)*e1 - np.dot(v3.T,e2)*e2\ne3 = w3/np.linalg.norm(w3) \n\n# V.T gives us significant stock combinations in stock space that experience variance over the period\n\nV = np.hstack([e1, e2, e3])\nV_t = V.T\n\nsv1 = S[0,0]\nsv2 = S[1,1]\nsv3 = S[2,2]\n\nu1 = 1/sv1 * A @ e1\nu2 = 1/sv2 * A @ e2\nu3 = 1/sv3 * A @ e3\n\n# This helps us with projections onto stock-return space to capture variance\n\nU = np.hstack([u1, u2, u3])\n\n# This follows from the well defined decompostion A = USV.T\n\nprint(\"Applying SVD to A_centered, we are left with the following decomposition: \")\nprint(A_centered, \" == \")\nprint(U)\nprint(S)\nprint(V_t)\n\nprint(\"Our singular values are, \", sv1, \"    ,\", sv2, \"and trivially, \", sv3)\n\n# These are the main directions of stock space that experience well defined variance by singular values\n\npc1 = V_t[:,0].reshape(-1,1)\npc2 = V_t[:,1].reshape(-1,1)\n\npc12 = np.hstack([pc1, pc2])\n\nprint(\"Our principle components are, PC1: \", pc1, \"   and PC2:\", pc2)\n\n# We are seeing how much we can reduce our dimensions\n# Less abstractly, this answers, \"How well do our combinations of stock components explain portfolios variance over period?\"\n\npc1_proj = A_centered @ pc1\npc12_proj = A_centered @ pc12\n\nprint(\"Hence our projection of pc1 onto stock-return space is,\", pc1_proj)\nprint(\"Hence our projection of pc2 onto stock-return space is,\", pc12_proj)\n\n# We see singular value of PC1 is 0.02 >> 0.005,0. Hence PC1 which is BHP dominated explains most variance in our portfolio over period (~80%)\n# PC2 is RIO dominated, PC3 is RMS dombinated. Both have small singular values (hence RMS is trival in variance explainations \n# PC1 projection shows returns went minor but negative along PC1 (hence BHP domination) for period 1.\n# PC1[2,1] = 0.030 implies returns moved strongly positive with PC1 and again hence BHP. PC1[3,1] = -0.02 shows returns moved strongly against PC1\n# PC1 explains most variance. PC1+PC2 projection shows period 2,3 moved only slightly with PC2 (hence RIO), and against RIO for period 1. \n# Hence we have explained majority variability with BHP and RIO, this is dimension reduction of varability of returns. Hence we have applied PCA",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Applying SVD to A_centered, we are left with the following decomposition: \n[[-0.00471667  0.00867     0.00109333]\n [ 0.02822333 -0.01383    -0.00448667]\n [-0.02350667  0.00516     0.00339333]]  == \n[[-0.73439591 -0.78859986         nan]\n [ 0.64584804  0.65878628         nan]\n [-1.2977471   1.13041953         nan]]\n[[0.02860978 0.         0.        ]\n [0.         0.00548778 0.        ]\n [0.         0.         0.        ]]\n[[ 0.91223336 -0.38440815 -0.1416357 ]\n [-0.38810693 -0.9216129   0.00163393]\n [ 0.13116139 -0.05347927  0.9899175 ]]\nOur singular values are,  0.0286097812260974     , 0.005487775948552484 and trivially,  0.0\nOur principle components are, PC1:  [[ 0.91223336]\n [-0.38810693]\n [ 0.13116139]]    and PC2: [[-0.38440815]\n [-0.9216129 ]\n [-0.05347927]]\nHence our projection of pc1 onto stock-return space is, [[-0.00752418]\n [ 0.03052531]\n [-0.02300112]]\nHence our projection of pc2 onto stock-return space is, [[-0.00752418 -0.00623573]\n [ 0.03052531  0.00213657]\n [-0.02300112  0.00409916]]\n"
        }
      ],
      "execution_count": 101
    },
    {
      "id": "92779d67-4699-4d23-847b-7685da09540f",
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}